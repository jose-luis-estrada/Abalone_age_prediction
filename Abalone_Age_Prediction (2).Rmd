---
title: "Abalone Age Prediction"
author: "Jose Luis Estrada, Nava Roohi, and Ashutosh Singh"
date: "6/20/2021"
output:
  word_document: default
  pdf_document: default
---

```{r global.options, include = FALSE}
knitr::opts_chunk$set(
    cache       = TRUE,     # if TRUE knitr will cache the results to reuse in future knits
    fig.align   = 'center', # how to align graphics in the final doc. 'left', 'right', 'center'
    fig.path    = 'figs/',  # file path to the directory where knitr shall store the graphics files
    #results     = 'asis',   # knitr will pass through results without reformatting them
    echo        = TRUE,     # in FALSE knitr will not display code in the code chunk above it's results
    message     = TRUE,     # if FALSE knitr will not display any messages generated by code
    strip.white = TRUE,     # if FALSE knitr will not remove white spaces at the beg or end of code chunk
    warning     = FALSE)    # if FALSE knitr will not display any warning messages in the final document
```

Traditionally, the process to predict the age of the abalone is by cutting the shell through the cone, staining it, and counting the number of rings through a microscope. The abalone dataset includes numeric attributes with a different types of measurements with the goal to predict the age of an abalone more efficiently.

```{r}
abalone <- read.csv('abalone.csv', header = TRUE)
abalone$Age <- abalone$Rings+1.5
abalone <- subset(abalone, select = -c(Rings))
```

The table has 4,177 observations and nine columns. The variable Age replaced the attribute Rings since each ring is equivalent to the number of rings plus 1.5 (Hossain). This will be helpful at a later stage of the project when the dataset is split into training and test set. As a reminder, this project aims to calculate the Age of the abalone so that the dependent variable will be Age.

```{r}
summary(abalone)
```

Furthermore, the attributes in the abalone dataset are numeric in its majority, and Sex is the only categorical data (binary). The dataset is not missing any values, so no data cleaning is needed.

```{r}
str(abalone)
```

```{r}
sapply(abalone, function(x) sum(is.na(abalone)))
```

The correlation plot shows high correlations (between 0.75 and 0.99) within the independent variables, but a medium direct correlation with the target value (between 0.4 and .65)

```{r fig.width=10, fig.height=8.5}
library(corrplot)
corrplot(cor(abalone[c(2:9)]), method = "shade", addCoef.col = "white")
```




```{r}
library(Hmisc)
hist.data.frame(abalone)
```

```{r}
par(mfrow=c(3,3))
for(i in 2:9) {
	boxplot(abalone[,i], main=names(abalone)[i])
}
```


```{r}
boxplot(abalone$Length)
```


```{r}
boxplot(abalone$Shucked.weight)
```

```{r}
boxplot(abalone$Viscera.weight)
```

```{r}
boxplot(abalone$Shell.weight)
```

```{r}
boxplot(abalone$Age)
```

```{r}
ggplot(data=abalone,aes(x=Sex,fill=Sex))+geom_bar()
```

```{r}
abalone2$Sex <- factor(abalone2$Sex)
```

```{r}
#ggplot(abalone2, aes(x=Sex, y= Age)) + 
       # geom_violin()
```

```{r}
pairs(abalone[2:9])
```

```{r}
set.seed(100)
abalone3<- abalone[,-c(1)]
partition<-createDataPartition(y=abalone3$Age,p=0.80,list = FALSE)


abalone_train<-abalone3[partition, ]
abalone_test<-abalone3[-partition, ]
control <- trainControl(method="repeatedcv", number=10)
```

```{r}
set.seed(100)
glm_fit<- train(Age~., data=abalone_train, method="glm", metric="RMSE",trControl=control)
glm_pred_tr <- predict(glm_fit, newdata=abalone_train[,c(1:7)])
glm_PR_tr <- postResample(pred=glm_pred_tr, obs=abalone_train$Age)
rmses_training = c(glm_PR_tr[1])
r2s_training = c(glm_PR_tr[2])
methods = c("GLM")

glm_pred <- predict(glm_fit, newdata=abalone_test[,c(1:7)])
glm_PR <- postResample(pred=glm_pred, obs=abalone_test$Age)
rmses_testing = c(glm_PR[1])
r2s_testing = c(glm_PR[2])

```


```{r}
### Penalized Models
glmnGrid <- expand.grid(.alpha = c(0, .1, .2, .4, .6, .8, 1),
 .lambda = seq(.01, .2, length = 40))
set.seed(100)
glmnet_fit <- train(Age~., data=abalone_train, method = "glmnet", tuneGrid = glmnGrid, preProc = c("center", "scale"), metric = "RMSE", trControl = control)
glmnet_pred_tr <- predict(glmnet_fit, newdata=abalone_train[,c(1:7)])
glmnet_PR_tr <- postResample(pred=glmnet_pred_tr, obs=abalone_train$Age)
rmses_training = c(rmses_training, glmnet_PR_tr[1])
r2s_training = c(r2s_training, glmnet_PR_tr[2])
methods = c(methods,"GLMNET")

glmnet_pred <- predict(glmnet_fit, newdata=abalone_test[,c(1:7)])
glmnet_PR <- postResample(pred=glmnet_pred, obs=abalone_test$Age)
rmses_testing = c(rmses_testing, glmnet_PR[1])
r2s_testing = c(r2s_testing, glmnet_PR[2])

```

```{r}
### Enet
enetGrid <- expand.grid(.lambda = c(0, .001, .01, .1),
.fraction = seq(0.05, 1, length = 20))
set.seed(100)
enet_fit <- train(Age~., data=abalone_train, method = "enet", preProc = c("center", "scale"), tuneGrid = enetGrid, metric = "RMSE", trControl = control)
enet_pred_tr <- predict(enet_fit, newdata = abalone_train[,c(1:7)])
enet_PR_tr <- postResample(pred = enet_pred_tr, obs=abalone_train$Age)
rmses_training = c(rmses_training, enet_PR_tr[1])
r2s_training = c(r2s_training, enet_PR_tr[2])
methods = c(methods,"ENET")

enet_pred <- predict(enet_fit, newdata=abalone_test[,c(1:7)])
enet_PR <- postResample(pred=enet_pred, obs=abalone_test$Age)
rmses_testing = c(rmses_testing, enet_PR[1])
r2s_testing = c(r2s_testing, enet_PR[2])

```


```{r}
### PLS

set.seed(100)
pls_fit <- train(Age~., data=abalone_train, method = "pls", preProc = c("center", "scale"), tuneLength = 15, metric = "RMSE", trControl = control)
pls_pred_tr <- predict(pls_fit, newdata=abalone_train[,c(1:7)])
pls_PR_tr <- postResample(pred=pls_pred_tr, obs=abalone_train$Age)
rmses_training = c(rmses_training, pls_PR_tr[1])
r2s_training = c(r2s_training, pls_PR_tr[2])
methods = c(methods, "PLS")


pls_pred <- predict(pls_fit, newdata=abalone_test[,c(1:7)])
pls_PR <- postResample(pred=pls_pred, obs=abalone_test$Age)
rmses_testing = c(rmses_testing, pls_PR[1])
r2s_testing = c(r2s_testing, pls_PR[2])

```


```{r}
library(earth)
library(e1071)
library(MASS)
```


```{r}
### MARS
set.seed(100)
earth_fit <- train(Age~., data=abalone_train, method = "earth", tuneGrid = expand.grid(.degree = 1,.nprune = 2:25), metric = "RMSE", trControl = control)
earth_pred_tr <- predict(earth_fit, newdata = abalone_train[,c(1:7)])
earth_PR_tr <- postResample(pred = earth_pred_tr, obs=abalone_train$Age)
rmses_training = c(rmses_training, earth_PR_tr[1])
r2s_training = c(r2s_training, earth_PR_tr[2])
methods = c(methods,"MARS")

earth_pred <- predict(earth_fit, newdata=abalone_test[,c(1:7)])
earth_PR <- postResample(pred=earth_pred, obs=abalone_test$Age)
rmses_testing = c(rmses_testing, earth_PR[1])
r2s_testing = c(r2s_testing, earth_PR[2])

```


```{r}
### Svm
set.seed(100)
svm_fit <- train(Age~., data=abalone_train, method = "svmRadial", preProc = c("center", "scale"), metric = "RMSE", trControl = control)
svm_pred_tr <- predict(svm_fit, newdata = abalone_train[,c(1:7)])
svm_PR_tr <- postResample(pred = svm_pred_tr, obs=abalone_train$Age)
rmses_training = c(rmses_training, svm_PR_tr[1])
r2s_training = c(r2s_training, svm_PR_tr[2])
methods = c(methods,"SVM")

svm_pred <- predict(svm_fit, newdata=abalone_test[,c(1:7)])
svm_PR <- postResample(pred=svm_pred, obs=abalone_test$Age)
rmses_testing = c(rmses_testing, svm_PR[1])
r2s_testing = c(r2s_testing, svm_PR[2])
```


```{r}
### Knn Model
set.seed(100)
knn_fit <- train(Age~., data=abalone_train, method="knn",
 preProc=c("center","scale"), tuneLength=10, metric = "RMSE", trControl = control)
knn_pred_tr <- predict(knn_fit, newdata = abalone_train[,c(1:7)])
knn_PR_tr <- postResample(pred = knn_pred_tr, obs=abalone_train$Age)
rmses_training = c(rmses_training, knn_PR_tr[1])
r2s_training = c(r2s_training, knn_PR_tr[2])
methods = c(methods,"KNN")

knn_pred <- predict(knn_fit, newdata=abalone_test[,c(1:7)])
knn_PR <- postResample(pred=knn_pred, obs=abalone_test$Age)
rmses_testing = c(rmses_testing, knn_PR[1])
r2s_testing = c(r2s_testing, knn_PR[2])

```

```{r}
resamp = resamples(
list(knn=knn_fit,svm=svm_fit,mars=earth_fit, PLS=pls_fit, enet=enet_fit, glmnet=glmnet_fit, gml=glm_fit) )
print(summary(resamp))
dotplot(resamp, metric="RMSE")

```

```{r}
res_training = data.frame(rmse=rmses_training, r2=r2s_training)
rownames(res_training) = methods
training_order = order(-res_training$rmse)

res_training = res_training[ training_order, ]  
res_testing = data.frame( rmse=rmses_testing, r2=r2s_testing )
rownames(res_testing) = methods
res_testing = res_testing[ training_order, ] 

library(pander)
library(dplyr)
res_training %>% pander(style = "simple", split.table = Inf, justify = "left",
caption="Model Comparison For Train ")

res_testing %>% pander(style = "simple", split.table = Inf, justify = "left",
caption="Model Comparison For Test")
```

